---
layout: post
title: 'Data'
subtitle: 'What data did we used & how we preprocessed it?'
date: 2023-02-31 10:45:13 -0400
background: '/img/posts/06.jpg'
author: Jonathan Hecht
---
# Notes & personal notes
>
> just for a first writing and structuring in german
>
> (citation -> maybe direct link & reference website with fixed entries??) -> yes but with footnote
>
> citation with pages or without?
>
> Title image???? -> i have no idea how to select a good one :(
>
> genrellen theoretischen überbau erklären -> also warum quell und ziel daten etc. -> von grob zu klein
>
> be careful with the length of the text 
>
> immer wenn ich kritisiere sich auf andere stellen bezoehen oder direkt mit quellen erklären warum das problematisch ist
>
> An example for references:
> Here is a simple footnote[^1]. With some additional text after it.
>
> [^1]: My reference.

---

Um die Forschungsfrage zu beantworten wurden zwei unterschiedliche Ansätze zur Datenvorbereitung durchgeführt. Dabei zielen beide Ansätze darauf die bekannten Bedingungen und bekannte Inforamtionen aus dem orginalen GANmapper Artikel einzubeziehen. Der zweite und nicht getestete Versuch ist dabei eine Weiterentwicklung des ersten Ansatzes und übernimmt entsprechend weite Teile des ersten Ansatzes. Die Hintergründe wieso der zweite Ansatz in der Praxis nicht getestet werden konnte, wird in im [Diskussion](2023-07-07-discussion.md) genauer aufgezeigt. 

## Known requirements from the GANmapper paper
Wie bereits bekannt ist wurden innerhalb des Ganmapper Papers verschiedene Ansätze in Bezug auf die Daten und deren Konfiguration getestet. Wir verwenden hier nur deren beste Ergebnisse, um keine unnötigen Experiemente durchzuführen. Aus dem Paper können die geeigneten Einstellungen, wie folgt zusammengefasst werden:
* OpenStreetMap building and street data
* Coloured Road Hierarchy Diagrams (CRHD) proposed by Chen et al. (2021)
* NIcht alle Straßenzüge aus OSM wurden verwendet
* 256x256 resolution
* Zoom level 16 of the [Slippy map format](https://wiki.openstreetmap.org/wiki/Slippy_map)/XYZ-Tiles as a compromise between **XY** 
* **Addtional THINGS????**

## First approach
Zunächst wurden die OSM Daten von Hamburg, Niedersachsen und Schleswig-Holstein von der Website [www.geofabrik.de](https://download.geofabrik.de/) heruntergeladen und zusammengeführt. Um Anschluss wurden die Straßen und Gebäudegrundrisse auf die minimale Bounding Box der administrativen Grenzen von Hamburg zugeschnitten. Im eine Differenzierung nach Bevölkerungsdichten zu ermöglichen, wurden entsprechende Daten von [eurostat](https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/population-distribution-demography/geostat) heruntergeladen und zugeschnitten. Die Unterteilung nach Bevölkerungsdichten erfolgte durch eine Unterteilung in drei Quantile (<33%,>33%-<66%,>66%). Dies soll eine Unterteilung in niedrige, mittlere und hohe Bevölkerugnsdichte vereinfacht darstellen. Die entsprechende Verteilung inklusive der Grenzwerte können hier betrachtet werden: 

<img class='img-fluid' src='/GANmapper-Project/img/posts/hist_pop_2018.svg' alt='Histogram inklusive Quantile der Bevölkerungsdicht ein Hamburg und Umgebung in 2018'>
<span class='caption text-muted'>Figure 1: Histogram inklusive Quantile der Bevölkerungsdichte in Hamburg und Umgebung in 2018</span>

Nach Einteilung in drei Klassen inklusive des Untersuchungsgebietes folgt aus dieser Abbildung: 
<img class='img-fluid' src='/GANmapper-Project/img/posts/map_pop_2018.svg' alt='Bounding Box und Bevölkerungsverteilung in Hamburg in Umgebung in 2018'>
<span class='caption text-muted'>Figure 2: Bounding Box und Bevölkerungsverteilung in Hamburg in Umgebung in 2018</span>

Anschließend wurden die Straßen- und Gebäudedaten auf die jeweilige Bevölkerungsdichte zugeschnitten.
Bevor die XYZ-Tiles nun als Quell- und Zieldaten erzeugt werden konnten, mussten die Straßenzüge und Gebäude entsprechend der Vorgaben visualisiert werden. In Bezug auf die Gebäude wurden die Grundrisse einfach schwarz eingefärbt. Bei den Straßenzügen die als CRHD dargestellt werden, wurde auf das [GitHub Repository](https://github.com/ualsg/Road-Network-Classification/blob/main/crhd_generator.py) von Chen et al. (2021) zurückgegriffen. Hierzu musste die Annahme getroffen werden, dass die Autoren des GANmapper Papers exakt die entsprechenden Straßenzügen und Farben verwendet haben. In Bezug auf die Linienbreite wurden die Verhältnisse des Repository aufgegriffen und die Startbreite geschätzt. Im Anschluss konnten die Quell- und Zieldaten für die jeweilige Bevölkerungsdichte um XYZ-Format erzeugt werden. Einige Beispiele sehen so aus: 
<img class='img-fluid' src='/GANmapper-Project/img/example_approach_1.drawio.png' alt='fig_result'>
<span class='caption text-muted'>Figure 3: Beispieltrainingdaten für den ersten Ansatz</span>
Diese Datenpaare wurden im letzten Schritt mittels des existierenden Skriptes vorprozessiert. Wesentliche Schritte des Prozesses waren:
* Das aussortieren von Bildern ohne Gebäudegrundrisse.
* Das aussortieren von Bildern mit wenigen Gebäudegrundrissen bzw. im Allgemeinen Bilder, wo weniger weiße Pixel inkludiert waren. Hierbei wurden die beschrieben Werte des Repos von maximal 170000 weißen Pixeln bei Zoom Level 16 verwendet, d.h. bei
    * <math>
        <mrow> 
            <mrow>  
                <mn>256</mn>  
                <mo>&sdot;</mo>  
                <mn>256</mn>
                <mo>&sdot;</mo> 
                <mn>3</mn>
            </mrow>
            <mo>=</mo>  
            <mn>196608</mn> 
            <mspace width="5px" />
            <mi> Gesamtpixeln</mi>
        </mrow>
        </math>
    * <math>
        <mfrac>
            <mrow>
            <mn>170000</mn>
            </mrow>
            <mn>196608</mn>
        </mfrac>
        <mo>&sdot;</mo>
        <mn>100</mn>
        <mo>&asymp;</mo>
        <mn>86.45%</mn>
        <mspace width="5px" />
        <mi>maximal weißen Pixeln, also </mi>
        <mspace width="5px" />
        <mn>13.55%</mn>
        <mspace width="5px" />
        <mi>nicht weißen Pixeln. </mi>
        </math>
* Im nächsten Schritt wurden, die Gesamtdaten in Trainings-, Test- und Validierungsdaten (70%,15%,15%) aufgeteilt. 
* Zuletzt wurden die Quell- und Zieldaten zu einem größeren Bild zusammengeführt. 

Nach der Vorprozessierung aus ungefähr 12600 Ausgangsbildern können die Anzahl an Bildpaaren je Bevölkerungsdichte aus Tabelle 1 entnommen werden.


<div style="overflow-x:auto;">
  <table>
    <tr>
        <th>Population Density</th>
        <th>Tiles after removing blank tiles</th>
        <th>Training tiles after pre-processing</th>
    </tr>
    <tr>
        <td>High</td>
        <td>3765</td>
        <td>1758</td>
    </tr>
    <tr>
        <td>Medium</td>
        <td>3110</td>
        <td>311</td>
    </tr>
        <tr>
        <td>Low</td>
        <td>1690</td>
        <td>72</td>
    </tr>
  </table>
</div>
<span class='caption text-muted'>Table 1: Anzahl an Datenpaaren nach der Vorprozessierung je Bevölkerungsdichte</span>

### Drawbacks of this approach 
Zwar wurde dieser Ansatz genutzt und die Ergebnisse wurden teilweise mittels dieser Daten erzeugt. Jedoch wurde bereits im Laufe der Bearbeitung festgestellt, dass es einige Nachteile gibt, die hier bereits erläutert werden sollen, um im Anschluss die alternative und verbesserte Variante der Erzeugung von Daten aufzuzeigen.
Als erstes muss die Aktualität und insbesondere die räumliche Auflösung der Bevölkerugnsdaten kritisiert werden. Dabei führt die räumliche Auflösung dazu, dass in den Grenzbereichen der einzelen Bevölkerungspolygone die Rastertiles abgeschnitten werden (vgl. Figure 3). Hinzu kommt, dass innerhalb der Bevölkerungsverteilung teilweise keine Daten vorhanden sind (vgl. Figure 2), wobei dies natürlich nicht einschließt, dass dort keine Gebäude sein können. Somit führt die derartige Zuschneidung der Daten bereits zum Verlust von möglichen Trainingsdaten führen. Außerdem wird aus Tabelle 1 erkenntlich, dass die Aussortierung von Bildern mit nicht ausreichend gefärbten Pixeln zu sehr geringen Anzahl an Trainingpaaren führt und die vorhandenen Trainingspaare innerhalb der Bevölkerungsdichteklassen ähnlich außen. Dabei reichen die Anzahlen vermutlich nicht für einen gewöhnlichen Trainingsprozess aus. Die Auswirkung auf die Vergleichbarkeit zwischen den Datensätzen und den generellen Einfluss auf die Fragestellung wird in der [Diskussion](2023-07-07-discussion.md) näher aufgegriffen werden.
Als letztes muss die Verwendung einzig der vorgeschlagen Straßentypen kritisiert werden. Es wurden nur 11 von in Hamburg 28 möglichen Straßentypen verwendet

## Differences for the second approach
Wenn diese vielfältigen Nachteile und die mangelnde Vergleichbarkeit betrachtet werden, sollte der Ansatz der Datenvorbereitung abgewandelt werden. Der Grundlegende Ablauf bleibt gleich, jedoch wurde die Aufteilung nicht anhand der Bevölkerungsdichte eines Datensatzes vorgenommen, sondern einzig auf Basis der Pixelverteilung. Zweitens wurden die Straßentypen genauer untersucht und weitere Straßentypen ergänzt.

Bevor die Verteilung der weißen Pixel genauer untersucht werden konnte, musste zunächst ermittelt werden, welche Straßentypen der OSM Daten verwendet werden sollte. Die Aufsummierung der Längen ergibt folgendes Bild: 
<img class='img-fluid' src='/GANmapper-Project/img/posts/osm_hh_street_hist.svg' alt='Histogram of the length of different street types in Hamburg and Surroundings'>
<span class='caption text-muted'>Figure N: Histogram of the length of different street types in Hamburg and Surroundings</span>
Im vorigen Ansatz wurden bereits, die nachfolgenden Straßentypen verwendet:

```python
street_types = ['service', 'residential', 'tertiary_link', 'tertiary', 'secondary_link', 'primary_link',
                 'motorway_link', 'secondary', 'trunk', 'primary', 'motorway']
```

Auf Basis der Häufigkeitsverteilung wurde sich entschieden noch 'unclassified' und 'living_street' zu ergänzen. Viele der Straßenabschnitte mit geringeneren Wegelängen, wie 'bridleway' wurden auf Grund dieser nicht verwendet. Bei anderen Straßenklassen, wie 'cycleway' oder 'footway' schien der visuelle Check viele Dopplungen mit den anderen Straßentypen darzustellen. Außerdem schienen diese in weiten Teilen nicht vollständig. Im Anschluss wurden erneut XYZ-Tiles erzeugt. Die Liniendicke wurde dabei leicht erhöht.

Im Anschluss musste der Datensatz aufgeteilt werden. Die nachfolgende Abbildung zeigt die Häufung von weißen Pixeln innerhalb des gesamten Ausgangsdatensatze inklusive der Einteilung in drei Quantile.
<img class='img-fluid' src='/GANmapper-Project/img/posts/white_pixel_hist.svg' alt='Histogram of the amount of total white pixels in Hamburg and Surroundings'>
<span class='caption text-muted'>Figure N: Histogram of the amount of total white pixels in Hamburg and Surroundings</span>
Dabei wird die Anzahl an Pixeln ohne Farbwert durch Beispielsweise Gewässer oder Wälder deutlich. Im Anschluss wurden diese Werte verwendet, um eine leicht abgewandeltes Vorprozessierung mit den entsprechenden Werten durchzuführen. Die angepasste Funktion sieht wie folgt aus: 

```python
def combine_target_mask(mask_file_path, target_file_path, threshold_1,threshold_2, output_folder_high, output_folder_medium, output_folder_low,i):   
    img1 = cv2.imread(mask_file_path)
    img2 = cv2.imread(target_file_path)
    # resize
    img1 = cv2.resize(img1, (256,256))    
    img2 = cv2.resize(img2, (256,256))    
    # high
    if np.unique(img2, return_counts=True)[1][-1] > threshold_1:   
        h1, w1 = img1.shape[:2]
        h2, w2 = img2.shape[:2]
        #create empty matrix
        vis = np.zeros((max(h1, h2), w1+w2,3), np.uint8)
        #combine 2 images
        vis[:h1, :w1,:3] = img1
        vis[:h2, w1:w1+w2,:3] = img2
        cv2.imwrite(output_folder_high + str(i) + '.png', vis)
    # medium
    elif np.unique(img2, return_counts=True)[1][-1] <= threshold_1 and np.unique(img2, return_counts=True)[1][-1] >= threshold_2:
        h1, w1 = img1.shape[:2]
        h2, w2 = img2.shape[:2]
        vis = np.zeros((max(h1, h2), w1+w2,3), np.uint8)
        vis[:h1, :w1,:3] = img1
        vis[:h2, w1:w1+w2,:3] = img2    
        cv2.imwrite(output_folder_medium + str(i) + '.png', vis)
    # low
    elif np.unique(img2, return_counts=True)[1][-1] < threshold_2:
         h1, w1 = img1.shape[:2]
         h2, w2 = img2.shape[:2]
         vis = np.zeros((max(h1, h2), w1+w2,3), np.uint8)
         vis[:h1, :w1,:3] = img1
         vis[:h2, w1:w1+w2,:3] = img2
         cv2.imwrite(output_folder_low + str(i) + '.png', vis)
    else:
         vis = None
    return vis

```
<span class='caption text-muted'>Listing 1: Anzahl an Datenpaaren nach der Vorprozessierung je Bevölkerungsdichte</span>

Mit dieser Art der Vorbereitung wird nur noch indirekt auf die Bevölkerungsdichte geschlossen und die Pixeldichte insbesondere da auch Straßeneinbezogen werden, stellen nur einen Indikator für eine hohe Bevölkerungsdichte dar. Jedoch zeigt, die nachfolgende Abbildung, dass zumindest in Teilen eine geringere Bevölkerungsdichte zutreffen sollte. Außerdem konnten im Vergleich zum ersten Ansatz die Artefakte durchs das Teilen fasst vollständig eleminiert werden. Einen vergleichbarer Effekt kann auch bei der Anzahl der Trainingsdaten vorgefunden werden.


<img class='img-fluid' src='/GANmapper-Project/img/posts/example_approach_2.drawio.png' alt='Histogram of the length of different street types in Hamburg and Surroundings'>
<span class='caption text-muted'>Figure N: Beispieltrainingdaten für den zweiten Ansatz</span>

<div style="overflow-x:auto;">
  <table>
    <tr>
        <th>Amount of Colored Pixels</th>
        <th>Train Dataset</th>
        <th>Test Dataset</th>
        <th>Validation Dataset</th>
    </tr>
    <tr>
        <td>High</td>
        <td>2503</td>
        <td>313</td>
        <td>313</td>
    </tr>
    <tr>
        <td>Medium</td>
        <td>2503</td>
        <td>313</td>
        <td>313</td>
    </tr>
        <tr>
        <td>Low</td>
        <td>2578</td>
        <td>322</td>
        <td>323</td>
    </tr>
  </table>
</div>
<span class='caption text-muted'>Table 1: Anzahl an Datenpaaren nach der Vorprozessierung je Pixelwert</span>


---
#### References